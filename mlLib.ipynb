{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age  experience  salary\n",
       "0    Alice   30           5   70000\n",
       "1      Bob   25           2   50000\n",
       "2  Charlie   35          10  100000\n",
       "3    Diana   28           4   60000\n",
       "4    Ethan   40          15  120000"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    (\"Alice\", 30, 5, 70000),\n",
    "    (\"Bob\", 25, 2, 50000),\n",
    "    (\"Charlie\", 35, 10, 100000),\n",
    "    (\"Diana\", 28, 4, 60000),\n",
    "    (\"Ethan\", 40, 15, 120000)\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"age\", \"experience\", \"salary\"]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df.to_csv(\"mlLib.csv\", index=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MLLib Example\").getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|experience|salary|\n",
      "+-------+---+----------+------+\n",
      "|  Alice| 30|         5| 70000|\n",
      "|    Bob| 25|         2| 50000|\n",
      "|Charlie| 35|        10|100000|\n",
      "|  Diana| 28|         4| 60000|\n",
      "|  Ethan| 40|        15|120000|\n",
      "+-------+---+----------+------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience', 'salary']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = spark.read.csv(\"mlLib.csv\", header=True, inferSchema=True)\n",
    "training.show()\n",
    "training.printSchema()\n",
    "training.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['age', 'experience'] ---> new feature ---> independent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+--------------------+\n",
      "|   name|age|experience|salary|independent features|\n",
      "+-------+---+----------+------+--------------------+\n",
      "|  Alice| 30|         5| 70000|          [30.0,5.0]|\n",
      "|    Bob| 25|         2| 50000|          [25.0,2.0]|\n",
      "|Charlie| 35|        10|100000|         [35.0,10.0]|\n",
      "|  Diana| 28|         4| 60000|          [28.0,4.0]|\n",
      "|  Ethan| 40|        15|120000|         [40.0,15.0]|\n",
      "+-------+---+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler = VectorAssembler(inputCols=[\"age\", \"experience\"], outputCol=\"independent features\")\n",
    "\n",
    "df_assembled = featureassembler.transform(training)\n",
    "df_assembled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|independent features|salary|\n",
      "+--------------------+------+\n",
      "|          [30.0,5.0]| 70000|\n",
      "|          [25.0,2.0]| 50000|\n",
      "|         [35.0,10.0]|100000|\n",
      "|          [28.0,4.0]| 60000|\n",
      "|         [40.0,15.0]|120000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalised_data = df_assembled.select(\"independent features\", \"salary\")\n",
    "finalised_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 23:44:41 WARN Instrumentation: [98c4a12f] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train_data, test_data = finalised_data.randomSplit([0.75, 0.25])\n",
    "regresser = LinearRegression(featuresCol=\"independent features\", labelCol=\"salary\")\n",
    "regresser = regresser.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([2439.8625, 2628.866])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresser.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17113.402061865876"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresser.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------------+\n",
      "|independent features|salary|       prediction|\n",
      "+--------------------+------+-----------------+\n",
      "|         [35.0,10.0]|100000|94570.44673539535|\n",
      "+--------------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results = regresser.evaluate(test_data)\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5429.553264604649, 29480048.653178997)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError, pred_results.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (PySpark)",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
